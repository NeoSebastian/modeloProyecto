{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "113479fc-00ac-431e-9c6c-f596065f2c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pymysql\n",
      "  Downloading PyMySQL-1.1.1-py3-none-any.whl.metadata (4.4 kB)\n",
      "Downloading PyMySQL-1.1.1-py3-none-any.whl (44 kB)\n",
      "Installing collected packages: pymysql\n",
      "Successfully installed pymysql-1.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pymysql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ca56639-5722-4d9b-b01b-02888742fd8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sqlalchemy\n",
      "  Downloading sqlalchemy-2.0.41-cp310-cp310-win_amd64.whl.metadata (9.8 kB)\n",
      "Collecting greenlet>=1 (from sqlalchemy)\n",
      "  Downloading greenlet-3.2.3-cp310-cp310-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in d:\\programacion\\inteligencia_artificial\\primera_red_neuronal\\primerared\\lib\\site-packages (from sqlalchemy) (4.12.2)\n",
      "Downloading sqlalchemy-2.0.41-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ---------------------------------------- 2.1/2.1 MB 16.8 MB/s eta 0:00:00\n",
      "Downloading greenlet-3.2.3-cp310-cp310-win_amd64.whl (296 kB)\n",
      "Installing collected packages: greenlet, sqlalchemy\n",
      "\n",
      "   ---------------------------------------- 0/2 [greenlet]\n",
      "   ---------------------------------------- 0/2 [greenlet]\n",
      "   ---------------------------------------- 0/2 [greenlet]\n",
      "   ---------------------------------------- 0/2 [greenlet]\n",
      "   ---------------------------------------- 0/2 [greenlet]\n",
      "   ---------------------------------------- 0/2 [greenlet]\n",
      "   ---------------------------------------- 0/2 [greenlet]\n",
      "   ---------------------------------------- 0/2 [greenlet]\n",
      "   ---------------------------------------- 0/2 [greenlet]\n",
      "   ---------------------------------------- 0/2 [greenlet]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   -------------------- ------------------- 1/2 [sqlalchemy]\n",
      "   ---------------------------------------- 2/2 [sqlalchemy]\n",
      "\n",
      "Successfully installed greenlet-3.2.3 sqlalchemy-2.0.41\n"
     ]
    }
   ],
   "source": [
    "!pip install sqlalchemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb3f769d-16ac-4238-bba0-65146a99b0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pymysql\n",
    "from sqlalchemy import create_engine\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89b01afb-0b30-483d-86c6-bd905b354e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuración de conexión (¡mejor usar variables de entorno para las credenciales!)\n",
    "DB_CONFIG = {\n",
    "    'host': 'localhost',\n",
    "    'user': 'root',\n",
    "    'password': '34587093treak',  # Considera usar un método más seguro para almacenar esto\n",
    "    'database': 'entorno_simulado_emprendimientos'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a3c3ba7-0b66-400a-b090-809b86eac42d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportación completada exitosamente!\n",
      "DataFrame shape: (17, 2)\n",
      "Archivos creados: Municipios.csv, Municipios.parquet\n"
     ]
    }
   ],
   "source": [
    "# Municipio\n",
    "\n",
    "# 2. Crear conexión con SQLAlchemy (forma recomendada)\n",
    "try:\n",
    "    # Cadena de conexión formato: mysql+pymysql://usuario:contraseña@host/basedatos\n",
    "    engine = create_engine(\n",
    "        f\"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}/{DB_CONFIG['database']}\"\n",
    "    )\n",
    "    \n",
    "    # 3. Consulta SQL optimizada\n",
    "    query = \"\"\"\n",
    "         SELECT id_municipio, municipio\n",
    "         FROM emprendimientos_sociales.Municipio;\n",
    "    \"\"\"\n",
    "    \n",
    "    # 4. Leer datos con Pandas\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        df = pd.read_sql(query, engine)\n",
    "    \n",
    "    # 5. Exportar a múltiples formatos\n",
    "    # CSV (para compatibilidad universal)\n",
    "    df.to_csv('Municipios.csv', encoding='utf-8-sig', index=False)\n",
    "    \n",
    "    # Parquet (para deep learning - formato binario eficiente)\n",
    "    df.to_parquet('Municipios.parquet', engine='pyarrow')\n",
    "    \n",
    "    print(\"Exportación completada exitosamente!\")\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(f\"Archivos creados: Municipios.csv, Municipios.parquet\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error durante la conexión o exportación: {e}\")\n",
    "finally:\n",
    "    # Cerrar conexión automáticamente con el contexto de SQLAlchemy\n",
    "    if 'engine' in locals():\n",
    "        engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "77457e72-a24d-4cf4-97eb-46d247ebc670",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportación completada exitosamente!\n",
      "DataFrame shape: (19, 2)\n",
      "Archivos creados: tematicas.csv, tematicas.parquet\n"
     ]
    }
   ],
   "source": [
    "# TEMATICAS\n",
    "\n",
    "try:\n",
    "    # Cadena de conexión formato: mysql+pymysql://usuario:contraseña@host/basedatos\n",
    "    engine = create_engine(\n",
    "        f\"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}/{DB_CONFIG['database']}\"\n",
    "    )\n",
    "    \n",
    "    # 3. Consulta SQL optimizada\n",
    "    query = \"\"\"\n",
    "        SELECT id_tematica, nombre\n",
    "        FROM entorno_simulado_emprendimientos.Tematica;\n",
    "    \"\"\"\n",
    "    \n",
    "    # 4. Leer datos con Pandas\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        df = pd.read_sql(query, engine)\n",
    "    \n",
    "    # 5. Exportar a múltiples formatos\n",
    "    # CSV (para compatibilidad universal)\n",
    "    df.to_csv('tematicas.csv', encoding='utf-8-sig', index=False)\n",
    "    \n",
    "    # Parquet (para deep learning - formato binario eficiente)\n",
    "    df.to_parquet('tematicas.parquet', engine='pyarrow')\n",
    "    \n",
    "    print(\"Exportación completada exitosamente!\")\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(f\"Archivos creados: tematicas.csv, tematicas.parquet\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error durante la conexión o exportación: {e}\")\n",
    "finally:\n",
    "    # Cerrar conexión automáticamente con el contexto de SQLAlchemy\n",
    "    if 'engine' in locals():\n",
    "        engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f42f6da9-5b9a-45d3-af75-eeb2293a8bd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportación completada exitosamente!\n",
      "DataFrame shape: (80, 7)\n",
      "Archivos creados: emprendimientos.csv, emprendimientos.parquet\n"
     ]
    }
   ],
   "source": [
    "# EMPRENDIMIENTOS\n",
    "\n",
    "try:\n",
    "    # Cadena de conexión formato: mysql+pymysql://usuario:contraseña@host/basedatos\n",
    "    engine = create_engine(\n",
    "        f\"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}/{DB_CONFIG['database']}\"\n",
    "    )\n",
    "    \n",
    "    # 3. Consulta SQL optimizada\n",
    "    query = \"\"\"\n",
    "        SELECT id_emprendimiento, nombre_emprendimiento, descripcion, redes_sociales, sitio_web, id_municipio_origen, id_alcance\n",
    "        FROM entorno_simulado_emprendimientos.Emprendimiento;\n",
    "    \"\"\"\n",
    "    \n",
    "    # 4. Leer datos con Pandas\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        df = pd.read_sql(query, engine)\n",
    "    \n",
    "    # 5. Exportar a múltiples formatos\n",
    "    # CSV (para compatibilidad universal)\n",
    "    df.to_csv('emprendimientos.csv', encoding='utf-8-sig', index=False)\n",
    "    \n",
    "    # Parquet (para deep learning - formato binario eficiente)\n",
    "    df.to_parquet('emprendimientos.parquet', engine='pyarrow')\n",
    "    \n",
    "    print(\"Exportación completada exitosamente!\")\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(f\"Archivos creados: emprendimientos.csv, emprendimientos.parquet\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error durante la conexión o exportación: {e}\")\n",
    "finally:\n",
    "    # Cerrar conexión automáticamente con el contexto de SQLAlchemy\n",
    "    if 'engine' in locals():\n",
    "        engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cedf1247-5527-4f61-a526-05b63f355b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportación completada exitosamente!\n",
      "DataFrame shape: (1520, 4)\n",
      "Archivos creados: publicaciones.csv, publicaciones.parquet\n"
     ]
    }
   ],
   "source": [
    "# PUBLICACIONES\n",
    "\n",
    "try:\n",
    "    # Cadena de conexión formato: mysql+pymysql://usuario:contraseña@host/basedatos\n",
    "    engine = create_engine(\n",
    "        f\"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}/{DB_CONFIG['database']}\"\n",
    "    )\n",
    "    \n",
    "    # 3. Consulta SQL optimizada\n",
    "    query = \"\"\"\n",
    "        SELECT id_publicacion, contenido, n_likes, id_emprendimiento\n",
    "        FROM emprendimientos_sociales.Publicacion;\n",
    "    \"\"\"\n",
    "    \n",
    "    # 4. Leer datos con Pandas\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        df = pd.read_sql(query, engine)\n",
    "    \n",
    "    # 5. Exportar a múltiples formatos\n",
    "    # CSV (para compatibilidad universal)\n",
    "    df.to_csv('publicaciones.csv', encoding='utf-8-sig', index=False)\n",
    "    \n",
    "    # Parquet (para deep learning - formato binario eficiente)\n",
    "    df.to_parquet('publicaciones.parquet', engine='pyarrow')\n",
    "    \n",
    "    print(\"Exportación completada exitosamente!\")\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(f\"Archivos creados: publicaciones.csv, publicaciones.parquet\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error durante la conexión o exportación: {e}\")\n",
    "finally:\n",
    "    # Cerrar conexión automáticamente con el contexto de SQLAlchemy\n",
    "    if 'engine' in locals():\n",
    "        engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f825d556-6153-4811-bbb3-705e6f5d8215",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportación completada exitosamente!\n",
      "DataFrame shape: (7920, 3)\n",
      "Archivos creados: comentarios.csv, comentarios.parquet\n"
     ]
    }
   ],
   "source": [
    "# COMENTARIOS\n",
    "\n",
    "try:\n",
    "    # Cadena de conexión formato: mysql+pymysql://usuario:contraseña@host/basedatos\n",
    "    engine = create_engine(\n",
    "        f\"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}/{DB_CONFIG['database']}\"\n",
    "    )\n",
    "    \n",
    "    # 3. Consulta SQL optimizada\n",
    "    query = \"\"\"\n",
    "        SELECT id_comentario, comentario, id_publicacion\n",
    "        FROM emprendimientos_sociales.Comentario;\n",
    "    \"\"\"\n",
    "    \n",
    "    # 4. Leer datos con Pandas\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        df = pd.read_sql(query, engine)\n",
    "    \n",
    "    # 5. Exportar a múltiples formatos\n",
    "    # CSV (para compatibilidad universal)\n",
    "    df.to_csv('comentarios.csv', encoding='utf-8-sig', index=False)\n",
    "    \n",
    "    # Parquet (para deep learning - formato binario eficiente)\n",
    "    df.to_parquet('comentarios.parquet', engine='pyarrow')\n",
    "    \n",
    "    print(\"Exportación completada exitosamente!\")\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(f\"Archivos creados: comentarios.csv, comentarios.parquet\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error durante la conexión o exportación: {e}\")\n",
    "finally:\n",
    "    # Cerrar conexión automáticamente con el contexto de SQLAlchemy\n",
    "    if 'engine' in locals():\n",
    "        engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6032f305-3b8c-40b0-b4e2-30ad869ee257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportación de la tabla Alcance completada exitosamente!\n",
      "DataFrame shape: (2, 2)\n",
      "Archivos creados: alcance.csv, alcance.parquet\n"
     ]
    }
   ],
   "source": [
    "# ALCANCE\n",
    "\n",
    "try:\n",
    "    # Cadena de conexión formato: mysql+pymysql://usuario:contraseña@host/basedatos\n",
    "    engine = create_engine(\n",
    "        f\"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}/{DB_CONFIG['database']}\"\n",
    "    )\n",
    "    \n",
    "    # Consulta SQL para la tabla Alcance\n",
    "    query = \"\"\"\n",
    "        SELECT id_alcance, tipo\n",
    "        FROM emprendimientos_sociales.Alcance;\n",
    "    \"\"\"\n",
    "    \n",
    "    # Leer datos con Pandas\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        df = pd.read_sql(query, engine)\n",
    "    \n",
    "    # Exportar a múltiples formatos\n",
    "    # CSV (para compatibilidad universal)\n",
    "    df.to_csv('alcance.csv', encoding='utf-8-sig', index=False)\n",
    "    \n",
    "    # Parquet (para deep learning - formato binario eficiente)\n",
    "    df.to_parquet('alcance.parquet', engine='pyarrow')\n",
    "    \n",
    "    print(\"Exportación de la tabla Alcance completada exitosamente!\")\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(f\"Archivos creados: alcance.csv, alcance.parquet\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error durante la conexión o exportación de la tabla Alcance: {e}\")\n",
    "finally:\n",
    "    # Cerrar conexión automáticamente con el contexto de SQLAlchemy\n",
    "    if 'engine' in locals():\n",
    "        engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd44106a-cba7-45f9-b495-c8d3ac971b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportación de la tabla seguidores completada exitosamente!\n",
      "DataFrame shape: (80, 3)\n",
      "Archivos creados: seguidores.csv, seguidores.parquet\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    # Cadena de conexión formato: mysql+pymysql://usuario:contraseña@host/basedatos\n",
    "    engine = create_engine(\n",
    "        f\"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}/{DB_CONFIG['database']}\"\n",
    "    )\n",
    "    \n",
    "    # Consulta SQL para la tabla seguidores\n",
    "    query = \"\"\"\n",
    "        SELECT id_seguidores, id_emprendimiento, cantidad\n",
    "        FROM emprendimientos_sociales.seguidores;\n",
    "    \"\"\"\n",
    "    \n",
    "    # Leer datos con Pandas\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        df = pd.read_sql(query, engine)\n",
    "    \n",
    "    # Exportar a múltiples formatos\n",
    "    # CSV (para compatibilidad universal)\n",
    "    df.to_csv('seguidores.csv', encoding='utf-8-sig', index=False)\n",
    "    \n",
    "    # Parquet (para deep learning - formato binario eficiente)\n",
    "    df.to_parquet('seguidores.parquet', engine='pyarrow')\n",
    "    \n",
    "    print(\"Exportación de la tabla seguidores completada exitosamente!\")\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(f\"Archivos creados: seguidores.csv, seguidores.parquet\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error durante la conexión o exportación de la tabla seguidores: {e}\")\n",
    "finally:\n",
    "    # Cerrar conexión automáticamente con el contexto de SQLAlchemy\n",
    "    if 'engine' in locals():\n",
    "        engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "defc23cf-ab93-45d2-afe8-fce4e1d58f33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exportación de la tabla emprendimiento_tematica completada exitosamente!\n",
      "DataFrame shape: (163, 2)\n",
      "Archivos creados: emprendimiento_tematica.csv, emprendimiento_tematica.parquet\n"
     ]
    }
   ],
   "source": [
    "# EMPRENDIMIENTO_TEMATICA\n",
    "\n",
    "try:\n",
    "    # Cadena de conexión formato: mysql+pymysql://usuario:contraseña@host/basedatos\n",
    "    engine = create_engine(\n",
    "        f\"mysql+pymysql://{DB_CONFIG['user']}:{DB_CONFIG['password']}@{DB_CONFIG['host']}/{DB_CONFIG['database']}\"\n",
    "    )\n",
    "    \n",
    "    # Consulta SQL para la tabla emprendimiento_tematica\n",
    "    query = \"\"\"\n",
    "        SELECT id_emprendimiento, id_tematica\n",
    "        FROM emprendimientos_sociales.emprendimiento_tematica;\n",
    "    \"\"\"\n",
    "    \n",
    "    # Leer datos con Pandas\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        df = pd.read_sql(query, engine)\n",
    "    \n",
    "    # Exportar a múltiples formatos\n",
    "    # CSV (para compatibilidad universal)\n",
    "    df.to_csv('emprendimiento_tematica.csv', encoding='utf-8-sig', index=False)\n",
    "    \n",
    "    # Parquet (para deep learning - formato binario eficiente)\n",
    "    df.to_parquet('emprendimiento_tematica.parquet', engine='pyarrow')\n",
    "    \n",
    "    print(\"Exportación de la tabla emprendimiento_tematica completada exitosamente!\")\n",
    "    print(f\"DataFrame shape: {df.shape}\")\n",
    "    print(f\"Archivos creados: emprendimiento_tematica.csv, emprendimiento_tematica.parquet\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error durante la conexión o exportación de la tabla emprendimiento_tematica: {e}\")\n",
    "finally:\n",
    "    # Cerrar conexión automáticamente con el contexto de SQLAlchemy\n",
    "    if 'engine' in locals():\n",
    "        engine.dispose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eac9c5-5721-46b7-a13a-1c1b50f8a744",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
